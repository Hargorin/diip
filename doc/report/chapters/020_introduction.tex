
% ==============================================================================
%
%                             Introduction
%
% ==============================================================================
\chapter{Introduction}
% Field/Context
Self driving cars are getting more popular and virtual reality video games
increasingly find their way into people's living rooms. One thing they share is
the need for a digital copy of the world. Self driving cars are trained in such
worlds to
accelerate the development of the algorithm and virtual reality games are
becoming more realistic. The Zurich based company Nomoko \footnote{
\url{https://www.nomoko.world/}} is developing a
technology that will enable the creation of digital copies of the world. They
built a giga pixel camera and a 3D pipeline to make this happen. This pipeline
consists among other things of high volume image processing. Modern computers
and graphical processing units (GPU) are fast in sequentially processing data
but are designed to serve many different tasks and not a specific one. A
dedicated hardware approach designed for a specific image processing task would
expedite the 3D pipeline of creating digital copies of the world.
\\

% Project goal/aims
The goal of this project is to implement such an image processing task on a
Field
Programmable Gate Array (FPGA). FPGAs
consist of thousands of logical elements that can be configured and connected
together to form a complex logical operation. Together with on chip
memory they offer high throughput by processing the data parallel in contrast to
sequential. The data is transfered to the FPGA over an Ethernet LAN connection
for
fast transfer rates. To accelerate the computing even further, the system needs
to be scalable to multiple FPGA boards to distribute the workload.

% Build upon 
In preparation for this thesis, a semester project focused on two building
blocks for this work: The communication block and the image processing block
\cite{p5report}. The results were two seperate parts working but neither
connected nor optimized. This thesis builds upon the results of said work and
focuses on two main goals:
\\

% Primary objectives
\begin{enumerate}
    \item Increase throughput of the dataflow by improving the communication and putting thoughts on scalability
    \item Implement a more complex image processing algorithm to show the real
    benefit of using FPGA for image processing
\end{enumerate}
% \begin{figure}[t!]
%     \centering
%     \input{images/introduction/dataflow.tikz}
%     \caption{Data Flow}
%     \label{fig:datafl}
% \end{figure}

% Sections with NEW are written new in p6
% What is used to realize...
% NEW Dataflow
The existing communication solution is based on file transfer and stores
received data in memory. This worked as a proof of concept but is not optimal
for high throughput image processing. The communication part is extended with an
acknowledge mechanism that allows retransmission of lost packets and a streaming
interface that enables immediate processing of the image data. Furthermore a
memory management unit is introduced that caches image data to reduce bandwidth
usage.

% NEW Image processing
In the preceeding project a Sobel filter was implemented using Vivado HLS. It
uses a simple convolution matrix for edge detection. This operation was well
suited for the first image processing task and to become acquainted with a high
level synthesis tool. For this thesis a new image processing task is realized: A
local contrast enhancment operation. The algorithm is described and thoroughly
tested in C/C++ and then synthesized to HDL by the Xilinx Vivado HLS toolchain.
To improve throughput and compare the results of a high level synthesis versus a
low level HDL approach, the same filter is implemented in VHDL.

% NEW Scalability
The main intention behind using Ethernet as communication was that the
processing could be distributed onto multiple FPGA. Methods on scalability are
dissected and compared.

An Artix7 Evaluation Kit by Xilinx serves as a development and testing platform.
It is equipped with gigabit Ethernet LAN and an FPGA with sufficient logic
elements and memory for both the communication and image processing task.
\\

% NEW What is the result of the project
\todo[inline]{Insert total throughput, limits and theoretical maximums}
The result is a complete image processing pipeline that begins on a PC where the
input image is sent via Ethernet to the FPGA where it is processed and sent pack
to the PC. The throughput is XXX MB/s limited by XXX. The Wallis filter core
is capable of processing up to XXX megapixels per second. A benchmark shows the
performance differences betwen a CPU based and FPGA based solution. Concepts on
scalability show how the processing power of FPGAs can be exploited if multiple
FPGA would work on a network.
\\

% NEW How the document is built up
This report is split into six main parts: Theoretical background, mission,
image processing, dataflow, scalability and verification/benchmark.  The
theoretical background starting on page \pageref{chapt:theoreticalback} explains
the basics of image processing, FPGA, Ethernet communication and on chip
interfaces. Starting on page \pageref{chapt:mission} the chapter mission will
cover the starting point and presents the concept. Chapters 
\ref{chapt:image_processing} and \ref{chapt:dataflow} cover the actual
implementation process of the image processing and dataflow parts.
Before verifying these components in chapter \ref{chapt:ver_bench} the
scalability is studied in chapter \ref{chapt:scalability} starting on page
\pageref{chapt:scalability}.

